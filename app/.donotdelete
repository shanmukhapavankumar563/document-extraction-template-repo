from __future__ import annotations

import argparse
import json
import re
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple


SUPPORTED_EXTENSIONS = {".pdf", ".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}


@dataclass
class ExtractionResult:
    source_file: str
    document_type: str
    fields: Dict[str, object]
    line_items: List[Dict[str, object]]
    confidence: float
    notes: List[str]


def _import_or_none(module_name: str):
    try:
        return __import__(module_name)
    except Exception:
        return None


def ocr_from_image(image_path: Path, notes: List[str]) -> str:
    pil = _import_or_none("PIL.Image")
    pytesseract = _import_or_none("pytesseract")
    if pil is None or pytesseract is None:
        notes.append("OCR skipped for image: install pillow + pytesseract")
        return ""

    image_module = __import__("PIL.Image", fromlist=["Image"])
    pyt_module = __import__("pytesseract")

    try:
        img = image_module.open(str(image_path))
        return pyt_module.image_to_string(img) or ""
    except Exception as exc:
        notes.append(f"OCR image failure: {exc}")
        return ""


def text_from_pdf(pdf_path: Path, notes: List[str]) -> str:
    pdfplumber = _import_or_none("pdfplumber")
    if pdfplumber is None:
        notes.append("PDF text extraction skipped: install pdfplumber")
        return ""

    extracted = []
    try:
        pdfplumber_module = __import__("pdfplumber")
        with pdfplumber_module.open(str(pdf_path)) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                if text.strip():
                    extracted.append(text)
    except Exception as exc:
        notes.append(f"PDF parsing failure: {exc}")
        return ""

    text = "\n".join(extracted).strip()
    if text:
        return text

    notes.append("PDF had no embedded text; trying OCR fallback")
    return ocr_pdf_fallback(pdf_path, notes)


def ocr_pdf_fallback(pdf_path: Path, notes: List[str]) -> str:
    pdf2image = _import_or_none("pdf2image")
    pytesseract = _import_or_none("pytesseract")
    if pdf2image is None or pytesseract is None:
        notes.append("PDF OCR fallback skipped: install pdf2image + pytesseract")
        return ""
    try:
        pdf2image_module = __import__("pdf2image")
        pyt_module = __import__("pytesseract")
        pages = pdf2image_module.convert_from_path(str(pdf_path), dpi=250)
        parts = [pyt_module.image_to_string(page) or "" for page in pages]
        return "\n".join(parts)
    except Exception as exc:
        notes.append(f"PDF OCR fallback failure: {exc}")
        return ""


def extract_text(file_path: Path, notes: List[str]) -> str:
    suffix = file_path.suffix.lower()
    if suffix == ".pdf":
        return text_from_pdf(file_path, notes)
    return ocr_from_image(file_path, notes)


def classify_document(text: str) -> Tuple[str, float]:
    t = text.lower()
    invoice_terms = [
        "invoice",
        "invoice no",
        "bill to",
        "due date",
        "tax",
        "subtotal",
    ]
    packing_terms = [
        "packing list",
        "ship to",
        "po no",
        "purchase order",
        "carton",
        "net weight",
    ]
    inv_score = sum(1 for term in invoice_terms if term in t)
    pack_score = sum(1 for term in packing_terms if term in t)
    total = max(inv_score + pack_score, 1)
    confidence = max(inv_score, pack_score) / total
    if inv_score >= pack_score:
        return "invoice", confidence
    return "packing_list", confidence


def match_first(patterns: List[str], text: str, flags: int = re.IGNORECASE) -> Optional[str]:
    for pat in patterns:
        match = re.search(pat, text, flags)
        if match:
            val = match.group(1).strip(" :-\n\t")
            if val:
                return val
    return None


def normalize_date(date_str: Optional[str]) -> Optional[str]:
    if not date_str:
        return None
    date_str = date_str.strip()
    formats = [
        "%Y-%m-%d",
        "%d-%m-%Y",
        "%m-%d-%Y",
        "%d/%m/%Y",
        "%m/%d/%Y",
        "%d.%m.%Y",
        "%b %d, %Y",
        "%B %d, %Y",
    ]
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt).date().isoformat()
        except ValueError:
            continue
    return date_str


def extract_line_items(text: str) -> List[Dict[str, object]]:
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    items = []
    for line in lines:
        if len(items) >= 100:
            break
        if re.search(r"\b(total|subtotal|tax|grand total|amount due)\b", line, re.IGNORECASE):
            continue
        if re.search(r"\d", line) and re.search(r"[A-Za-z]", line):
            numbers = re.findall(r"-?\d+(?:\.\d+)?", line)
            if not numbers:
                continue
            qty = None
            price = None
            amount = None
            if len(numbers) >= 1:
                qty = numbers[0]
            if len(numbers) >= 2:
                price = numbers[-2]
                amount = numbers[-1]
            cleaned = re.sub(r"\s+", " ", line)
            items.append(
                {
                    "description": cleaned[:200],
                    "quantity": qty,
                    "unit_price": price,
                    "line_total": amount,
                }
            )
    return items


def extract_invoice_fields(text: str) -> Dict[str, object]:
    vendor = None
    non_empty = [ln.strip() for ln in text.splitlines() if ln.strip()]
    if non_empty:
        vendor = non_empty[0][:200]

    invoice_number = match_first(
        [
            r"invoice\s*(?:no|number|#)\s*[:\-]?\s*([A-Z0-9\-\/]+)",
            r"inv\s*(?:no|#)\s*[:\-]?\s*([A-Z0-9\-\/]+)",
        ],
        text,
    )
    invoice_date = match_first(
        [
            r"invoice\s*date\s*[:\-]?\s*([A-Za-z0-9,./\- ]+)",
            r"date\s*[:\-]?\s*([A-Za-z0-9,./\- ]+)",
        ],
        text,
    )
    invoice_date = normalize_date(invoice_date)
    return {
        "vendor_name": vendor,
        "invoice_number": invoice_number,
        "invoice_date": invoice_date,
    }


def extract_ship_to_block(text: str) -> Optional[str]:
    lines = text.splitlines()
    for idx, line in enumerate(lines):
        if re.search(r"\bship\s*to\b", line, re.IGNORECASE):
            block = []
            for j in range(idx + 1, min(idx + 8, len(lines))):
                ln = lines[j].strip()
                if not ln:
                    if block:
                        break
                    continue
                if re.search(r"\b(invoice|bill to|order|po|purchase order)\b", ln, re.IGNORECASE):
                    if block:
                        break
                block.append(ln)
            if block:
                return ", ".join(block[:5])[:300]
    return None


def extract_packing_fields(text: str) -> Dict[str, object]:
    order_number = match_first(
        [
            r"(?:order\s*(?:no|number)|purchase order|po)\s*(?:no|number|#)?\s*[:\-]?\s*([A-Z0-9\-\/]+)",
        ],
        text,
    )
    ship_to = extract_ship_to_block(text)
    return {
        "order_or_po_number": order_number,
        "ship_to_address": ship_to,
    }


def parse_document(file_path: Path) -> ExtractionResult:
    notes: List[str] = []
    text = extract_text(file_path, notes)
    if not text.strip():
        return ExtractionResult(
            source_file=str(file_path),
            document_type="unknown",
            fields={},
            line_items=[],
            confidence=0.0,
            notes=notes + ["No text extracted"],
        )

    doc_type, confidence = classify_document(text)
    if doc_type == "invoice":
        fields = extract_invoice_fields(text)
    else:
        fields = extract_packing_fields(text)
    line_items = extract_line_items(text)
    return ExtractionResult(
        source_file=str(file_path),
        document_type=doc_type,
        fields=fields,
        line_items=line_items,
        confidence=round(confidence, 4),
        notes=notes,
    )


def collect_inputs(input_path: Path) -> List[Path]:
    if input_path.is_file() and input_path.suffix.lower() in SUPPORTED_EXTENSIONS:
        return [input_path]
    if input_path.is_dir():
        return sorted(
            [
                p
                for p in input_path.rglob("*")
                if p.is_file() and p.suffix.lower() in SUPPORTED_EXTENSIONS
            ]
        )
    return []


def to_serializable(results: List[ExtractionResult]) -> List[Dict[str, object]]:
    return [
        {
            "source_file": r.source_file,
            "document_type": r.document_type,
            "confidence": r.confidence,
            "fields": r.fields,
            "line_items": r.line_items,
            "notes": r.notes,
        }
        for r in results
    ]


def write_json(results: List[ExtractionResult], out_file: Path) -> None:
    data = to_serializable(results)
    out_file.write_text(json.dumps(data, indent=2), encoding="utf-8")


def write_xlsx(results: List[ExtractionResult], out_file: Path) -> bool:
    openpyxl = _import_or_none("openpyxl")
    if openpyxl is None:
        return False
    openpyxl_module = __import__("openpyxl")
    wb = openpyxl_module.Workbook()

    ws_docs = wb.active
    ws_docs.title = "documents"
    ws_docs.append(
        [
            "source_file",
            "document_type",
            "confidence",
            "field_1_key",
            "field_1_value",
            "field_2_key",
            "field_2_value",
            "field_3_key",
            "field_3_value",
            "notes",
        ]
    )
    for r in results:
        f_items = list(r.fields.items())
        row = [r.source_file, r.document_type, r.confidence]
        for i in range(3):
            if i < len(f_items):
                row.extend([f_items[i][0], str(f_items[i][1]) if f_items[i][1] is not None else ""])
            else:
                row.extend(["", ""])
        row.append(" | ".join(r.notes))
        ws_docs.append(row)

    ws_items = wb.create_sheet("line_items")
    ws_items.append(["source_file", "document_type", "description", "quantity", "unit_price", "line_total"])
    for r in results:
        for item in r.line_items:
            ws_items.append(
                [
                    r.source_file,
                    r.document_type,
                    item.get("description", ""),
                    item.get("quantity", ""),
                    item.get("unit_price", ""),
                    item.get("line_total", ""),
                ]
            )
    wb.save(str(out_file))
    return True


def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Local-first document extraction")
    parser.add_argument("--input", type=str, default="samples", help="Input file or folder")
    parser.add_argument("--output", type=str, default="output", help="Output folder path")
    parser.add_argument(
        "--format",
        type=str,
        choices=["json", "xlsx", "both"],
        default="both",
        help="Output format",
    )
    return parser


def main() -> int:
    parser = build_arg_parser()
    args = parser.parse_args()

    input_path = Path(args.input).resolve()
    output_dir = Path(args.output).resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    files = collect_inputs(input_path)
    if not files:
        print(f"No supported input documents found at: {input_path}")
        return 1

    results = [parse_document(p) for p in files]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_path = output_dir / f"extraction_{timestamp}.json"
    xlsx_path = output_dir / f"extraction_{timestamp}.xlsx"

    wrote = []
    if args.format in {"json", "both"}:
        write_json(results, json_path)
        wrote.append(str(json_path))
    if args.format in {"xlsx", "both"}:
        ok = write_xlsx(results, xlsx_path)
        if ok:
            wrote.append(str(xlsx_path))
        else:
            print("openpyxl not installed: skipped .xlsx output")

    print(f"Processed {len(files)} file(s)")
    for path in wrote:
        print(f"Wrote: {path}")
    return 0


if __name__ == "__main__":
    sys.exit(main())

